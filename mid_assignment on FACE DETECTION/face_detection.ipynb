{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "# ignore information messgaes from tensorflow, but we will receieve error messages\n",
    "os.environ['TFF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train= (312, 512, 512, 3) Y_train= (312,)\n",
      "X_valid= (180, 512, 512, 3) Y_valid= (180,)\n",
      "X_test= (138, 512, 512, 3) Y_test= (138,)\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"./resources/X_train.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./resources/Y_train.pickle\",\"rb\")\n",
    "Y_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./resources/X_valid.pickle\",\"rb\")\n",
    "X_valid = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./resources/Y_valid.pickle\",\"rb\")\n",
    "Y_valid = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./resources/X_test.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./resources/Y_test.pickle\",\"rb\")\n",
    "Y_test = pickle.load(pickle_in)\n",
    "\n",
    "print(f\"X_train= {X_train.shape} Y_train= {Y_train.shape}\")\n",
    "print(f\"X_valid= {X_valid.shape} Y_valid= {Y_valid.shape}\")\n",
    "print(f\"X_test= {X_test.shape} Y_test= {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img = np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'E:\\\\cvprMidProject\\\\data_dir'\n",
    "TRAIN_DATA_DIR = os.path.join(DATA_DIR, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = []\n",
    "for i in os.listdir(TRAIN_DATA_DIR):\n",
    "    CATEGORIES.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABDULLAH AL SHAHRIAR', 'AHMED IMTIAZ', 'AL-NAFI', 'ASHIK AHAMED', 'BISHANATH TARAFDER', 'ESM-E MOULA CHOWDHURY ABHA', 'FAHIM RAHMAN', 'FAIZA BINTE ZAMAN', 'IMAM HASAN JAMI', 'MD ABU ZAYED KHAN', 'MD ATIK ULLAH KHAN', 'MD FARDIN AMIN RIYAD', 'MD IMTIAJ ALAM SAJIN', 'MD JAHID HASSAN', 'MD MUNTASIR AREFIN NAEEM', 'MD NAIMUR RAHMAN', 'MD SAJID ISLAM KHAN', 'MD SHANZID HASAN', 'MD TAREK MAHMUD', 'MD TOYABUR RAHAMAN', 'MD WAHIDUZZAMAN SUVA', 'MOHAMMAD BIN AB JALIL SHEAKH', 'MOHAMMAD NUR', 'MOHAMMED TANVIR HASSAN', 'NAFIS MUBASSHIR SHAH', 'NAHAR ISLAM NISHI', 'NAVID MAHFUZ NAYEEM', 'RAHAD-UL-ISLAM RABBY', 'REZWAN AHMAD', 'S M FAISAL', 'SABBIR AHMED', 'SADAT BIN MASUD', 'SATYAJIT DAS', 'SHEIKH AKIB ALMAS', 'SRABONE RAXIT', 'SYEDA HUMAIRA JABEEN', 'TAHFIM IBN KHAN', 'TAHMID AL RAFID SIDDIQUE', 'TARIKUL ISLAM NISHAT']\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16964\\3734770766.py:30: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(np.argmax(prediction, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model(\"./resources/alexnet_model.h5\", compile=False)\n",
    "\n",
    "# Function to preprocess the face image\n",
    "def preprocess(face_img):\n",
    "    face_img = cv2.resize(face_img, (512, 512))  # Resize to the size expected by your model\n",
    "    face_img = face_img-mean_img\n",
    "    face_img = np.expand_dims(face_img, axis=0)\n",
    "    return face_img\n",
    "\n",
    "# Start video capture from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 4)\n",
    "\n",
    "    # Loop through detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        processed_face = preprocess(face_img)\n",
    "\n",
    "        # Predict mask status\n",
    "        prediction = model.predict(processed_face)\n",
    "        label = int(np.argmax(prediction, axis=1))\n",
    "        \n",
    "        # Label the prediction\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, CATEGORIES[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                \n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Break the loop with the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpr tf py3.10",
   "language": "python",
   "name": "cvpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
